---
title: MySQL
description: MySQL
date: 2023-08-02
tags: 
 - 数据库
 - MySQL
---

# MySQL

## SQL语句执行流程

### 1.连接器
在执行SQL语句之前，需要连接MySQL服务器
```bash
# -h 指定MySQL服务器IP地址
# -u 指定用户名
# -p 指定密码
mysql -h$ip -u$user -p
```
经TCP三次握手后建立连接，连接器验证用户名和密码，若正确，获取用户权限。

### 2.查询缓存（MySQL8.0之前）

若SQL语句为查询(select)语句，MySQL会先去查询缓存中查找缓存数据，缓存数据是以kv形式保存在内存中的，k为查询语句，v为查询结果，但实际运行时，若表更新，则缓存会被清空，所以缓存命中率很低，在MySQL8.0之后，不再查询缓存

### 3.解析SQL

通过词法分析和语法分析判断SQL语句是否正确

### 4.执行SQL

1. 预处理阶段：检查查询语句中的表或字段是否存在，将*扩展为所有列；
2. 优化阶段：确定SQL查询语句的执行方案，选择最优的索引
3. 执行阶段：执行SQL语句

## 引擎

### InnoDB

InnoDB是MySQL默认的事务性存储引擎，其核心优势在于ACID事务的完整支持，这确保了在高并发环境下数据操作的**原子性、一致性、隔离性和持久性**。

InnoDB采用了**行级锁定**机制，能够最大程度地减少并发写入时的锁冲突，提高系统的并发处理能力。

InnoDB还支持**外键约束**，有助于维护数据之间的参照完整性，并通过**redo log和undo log**实现了可靠的**崩溃恢复**能力，保证数据在意外停机后的不丢失和一致性。

InnoDB引擎内部的**缓冲池**机制也能有效地缓存数据和索引，提升读写能力。因此，InnoDB适用于有**高并发、事务支持和数据完整性**需求的应用场景。

### MyISAM

MyISAM是一个**非事务性**的存储引擎，它**不支持ACID事务**，这意味着并发写入或系统崩溃时，数据的一致性无法得到保证。同样**不支持外键约束**。

MyISAM采用了**表级锁定**，即当一个写操作发生时，会锁定整个表，这在**高并发**写入场景下会导致严重的性能瓶颈。

MyISAM的主要特点是**读取速度快**，因为它将数据和索引分开存储，且结构相对简单。然而由于**缺乏事务支持和行级锁定**，MyISAM更适用于**读多写少**、对数据一致性要求不高的简单应用，如只读的报表查询或日志记录。

### Memory

Memory引擎将所有数据存储在**内存**中，具有**极高的读写速度**。因此也导致了其数据的**易失性**，一旦MySQL服务器关闭或重启，存储在Memory引擎中的数据将全部丢失。

Memory引擎支持**表级锁定**，该引擎通常适用于创建**临时表**，或者缓存一些**频繁访问且数据量不大、对持久性要求不高**的临时数据，以加速查询。

### Archive

Archive引擎主要用于存储**大量不经常访问的归档数据**。其最大的特点是对数据进行**高度压缩**，能够显著节省存储空间。

Archive引擎支持**高速数据插入**，但其**查询性能非常差**，通常只能进行全表扫描，且**不支持索引**。因此它适用于那些只需要将数据长期保存，并对查询性能要求不高的场景，如存储历史日志或传感器数据。

## 索引

### 索引分类

* 按数据结构分类：B+树索引、HASH索引、Full-Text索引；
* 按物理存储分类：聚簇索引（主键索引）、二级索引（辅助索引）；
* 按字段特性分类：主键索引、唯一索引、普通索引、前缀索引；
* 按字段个数分类：单列索引、联合索引（复合索引）；

### 索引失效

* 使用左或者左右模糊匹配时，即```like %xx```或者```like %xx%```这两种情况都会造成索引失效，因为**索引B+树按照索引值有序排序存储，只能根据前缀进行比较**；
* 在条件查询中对索引列使用函数，会造成索引失效，因为**索引保存的是字段的原始值，而不是经函数计算后的值**；
* 在条件查询中对索引列使用表达式计算，会造成索引失效，原因与上面相同；
* 碰到字符串和数字进行比较时，会自动把字符串转为数字，然后再进行比较，若字符串是索引列而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，而隐式类型转换是通过CAST函数实现的，等同于对索引列使用了函数，造成索引列失效；
* 联合索引需要遵循最左匹配原则，即按照最左优先进行索引匹配，否则会导致索引失效；
* 在WHERE子句中，若OR前的条件列是索引列，OR后的条件列不是索引列，那么索引会失效；

## 事务

### 事务的特性

* 原子性（Atomicity）：一个事务中的所有要做，要么都完成，要么都不完成，通过undo log保证；
* 一致性（Consistency）：事务操作先后，数据满足完整性约束，数据库保持一致性状态，通过原子性+持久性+隔离性保证；
* 隔离性（Isolation）：数据库允许对多个并发事务同时对数据进行读写能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，通过MVCC或锁机制保证；
* 持久性（Durability）：事务处理后，对数据的修改是永久的，即使系统故障不会丢失，通过redo log保证；

### 并行事务会引发什么问题

* 脏读：一个事务读到了另一个未提交事务的修改过的数据；
* 不可重复读：一个事务多次读取同一个数据出现了数据前后不一样的情况；
* 幻读：一个事务多次读取某个条件的记录数量出现记录数量前后不一致的情况；

这三种现象的严重性排序如下：脏读 > 不可重复读 > 幻读

### 事务隔离级别

* 读未提交：一个事务未提交时，其做的变更能被其他事务读到；
* 读提交：一个事务提交之后，其做的变更才能被其他事务读到；
* 可重复读：一个事务执行过程中看到的数据，与该事务启动时看到的数据是一致的（**MySQL InnoDB引擎的默认隔离级别**，但其通过**快照读**和**当前读**很大程度上避免了幻读）；
* 串行化：对记录加上读写锁，当多个事务发生读写冲突时，后访问的事务必须等前一个事务执行完成才能继续执行；

隔离水平高低排序如下：串行化 >可重复读 > 读已提交 > 读未提交

* 读未提交隔离级别下，可能发生脏读、不可重复读和幻读；
* 读提交隔离级别下：可能发生不可重复读和幻读；
* 可重复读隔离级别下：可能发生幻读现象；
* 串行化隔离级别下：均不可能发生；


### Read View工作机制

Read View是实现MVCC（多版本并发控制）的核心机制之一。它决定了一个事务在执行查询时，能看到哪些数据版本，不能看到你那些数据版本，以在不加锁的情况下实现“读一致性”。它不是一个物理快照，而是一个逻辑判断规则，用于查询时动态判断某一行的版本是否对当前事务可见。

若隔离级别为读提交，则每次执行select语句前都会创建一个新的Read View；若隔离级别为可重复读，则事务启动时创建Read View，整个事务期间复用同一个Read view。

:::tip
执行```begin/start transaction```命令后并不代表事务启动，而是在该命令后执行第一条select语句时才启动；执行```start transaction with consistent snapshot```命令，则会马上启动事务
:::

Read View有四个重要字段：
[](./assets/readview.webp)
* creator_trx_id：创建该Read View的事务id
* m_ids：创建Read View时，当前数据库中**活跃且未提交**的事务id列表
* min_trx_id：创建Read View时当前数据库中**活跃且未提交**的最小事务id
* max_trx_id：创建Read view时当前数据库中应该给下一个事务的id值

并且在聚簇索引的每个记录中，还有两个隐藏列：
[](./assets/隐藏列.png)
* trx_id：当一个事务对某条聚簇索引记录进行改动时，就会**把该事务id记录在trx_id隐藏列中**
* roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到undo日志中，而roll_pointer就是一个指针，指undo log。

当事务去访问记录时，有以下情况：
* 若当前行的trx_id < min_trx_id，表示当前版本记录在创建Read View前已由其他事务提交，则当前版本记录对当前事务**可见**；
* 若当前行的trx_id > max_trx_id，表示当前版本记录在创建Read View后由其他事务提交，则当前版本记录对当前事务**不可见**；
* 若min_trx_id <= trx_id <= max_trx_id，则需判断m_ids列表，若trx_id在m_ids列表中，表明当前版本记录的活跃事务还未提交，则当前版本记录对当前事务**不可见**，此时事务会从roll_pointer沿着undo log查询到trx_id < 当前事务Read View中的min_trx_id值的第一个版本；否则，表明当前版本记录的活跃事务已被提交，则当前版本记录对当前事务**可见**；

这种通过版本链来控制并发事务访问同一记录时的行为就叫MVCC（多版本并发控制）。

## 锁

### MySQL的锁

1. 全局锁
执行```flush tables with read lock```后，数据库处于只读状态，其他线程对数据的增删改和对表结构的更改均会被阻塞，执行```unlock tables```或断开会话释放全局锁；

应用场景：全库逻辑备份，防止在备份期间因数据或表结构的更新导致备份文件与预期不一致；

缺点：在备份时加上全局锁导致数据库处于只读状态，则备份期间无法更新数据导致业务停滞；

如何避免全局锁缺点：在备份数据库之前开启事务，则会创建Read View，在事务执行期间由于MVCC的支持，可以安全进行更新操作，前提是数据库引擎需支持**可重复读的隔离级别**；

2. 表级锁

表级锁有以下几种：
* 表锁：```lock tables x read;```表级的读锁，允许当前线程读被锁定的表，但阻止其他线程（包括当前线程）写，且当前线程无法访问其他表；```lock tables x write;```表级的写锁，允许当前线程对表读写，但阻止其他线程进行任何操作；使用```unlock tables```或退出会话释放所有表锁；
* 元数据锁（MDL）：MDL锁无需显示调用，在对表进行操作时会自动加锁，在事务提交后自动释放。对表进行CRUD操作时，加的是**MDL读锁**，对表结构进行更改时，加的是**MDL写锁**。若在MDL读锁期间，另一个线程申请MDL写锁，那么该线程包括后续所有读请求都会被阻塞（写锁优先级高于读锁）。
* 意向锁：为高效管理行锁，引入意向锁作为表级锁，用于“表明意图”。在对表中记录加上**共享锁**之前，需要在表级别加上**意向共享锁**，对表中记录加上**独占锁**之前，需要在表级别上加上**意向独占锁**。意向xx锁不会和行级锁发生冲突，只会和共享表锁和独占表锁发生冲突。意向锁的目的是为了快速判断表中是否有记录被加锁。
* AUTO-INC锁：主键的自增是通过对主键字段声明AUTO_INCREMENT属性实现的，之后可以不指定主键的值，数据库会自动递增赋值，这是通过AUTO-INC锁实现的。AUTO-INC锁会在执行完插入语句后立即释放但在插入大量数据时，这个表级锁会产生性能问题，所以MySQL5.1.22后，InnoDB提供了一种轻量级锁实现自增，使用系统变量```innodb_autoinc_lock_mode```控制选择用哪个锁，为0则使用AUTO-INC锁，为2使用轻量级锁，申请自增主键后释放锁，为1则在批量插入语句时，执行结束释放。


3. 行级锁

* 记录锁Record Lock：锁住一条记录，分为读/写锁，读锁```select ... lock in share mmode```，写锁```select ... for update```，事务提交自动释放；
* 间隙锁Gap Lock：用于解决可重复读隔离级别下的幻读现象，如在范围id(3, 5)的间隙锁下，其他事务无法插入id为4的记录，前开后开区间；插入意向锁是一种特殊的间隙锁，且只用于并发插入操作，间隙锁之间可以互相兼容，但插入意向锁与间隙锁之间是冲突的。
* Next-Key Lock：Record Lock + Gap Lock组合，锁定范围也锁定记录本身，前开后闭区间


### 死锁产生场景，如何避免死锁

死锁产生场景：交叉更新、间隙锁冲突（间隙锁是在select ... for update时加的，放插入）、插入意向锁冲突（插入时加的）、无索引条件更新（全表行锁）

死锁的必要条件：互斥、占有且等待、不可强占用、循环等待，发生死锁时，这些条件必成立，只要破坏任一条件死锁就不会成立。

* 设置事务等待锁的超时时间。当一个事务的等待时间超过参数```innodb_lock_wait_timeout```值时，对事务进行回滚以释放锁；
* 开启主动死锁检测。当发生死锁后，主动回滚死锁链条中的某个事务，让其他事务得以继续执行，死锁检测由参数```innodb_deadlock_detect```控制

## 日志

### undo log（回滚日志）

Innodb存储引擎生成的日志，实现了事务的**原子性**，主要用于事务回滚和MVCC。在事务没提交之前，MySQL会先记录更新前的数据到undo log日志文件中，当事务回滚时，利用undo log进行回滚。

每条undo log记录包含：事务id（trx_id）、回滚指针（roll_pointer，指向更早的undo版本，形成版本链）、主键值、旧值、操作类型

undolog两大作用：实现事务回滚、保证事务原子性；实现MVCC关键因素之一。

### redo log（重做日志）

Innodb存储引擎生成的日志，实现了事务的**持久性**，主要用于掉电等故障恢复。由于Buffer Pool是存放在内存中的，断点等故障会导致未落盘脏页数据丢失，为此使用redo log记录页的修改信息，后续采用WAL(Write-Ahead Logging)技术写到磁盘上。

redo log也不是直接写入磁盘的，他自己也有一个redo log buffer，产生redo log时，先写入buffer，再持久化到磁盘，刷盘时机有：MySQL正常关闭时；redo log buffer写入量大于redo log buffer内存空间的一半时；InnoDB后台线程每隔1秒；事务提交时；

redo log有1个重做日志文件组，其中包含了2个redo log文件ib_logfile0和ib_logfile1，重做日志文件组以循环写方式工作，边写边擦除，当脏页数据落盘后就会从redo log文件擦除；

:::tip
* redo log记录事务**修改后**的数据状态，记录的是更新**之后**的值，主要用于事务崩溃恢复，保持事务持久性；
* undo log记录事务**修改前**的数据状态，记录的是更新**之前**的值，主要用于事务回滚，保证事务的原子性；
:::

redo log两大作用：实现事务持久性，让MySQL拥有crash-safe（崩溃恢复）能力；将写操作从随机写变为顺序写，提升MySQL写磁盘性能；

### binlog（归档日志）

Server层生成的日志，主要用于数据备份和主从复制；binlog记录了表结构变更和表数据修改，不记录查询类操作；

binlog有三种格式类型：
* STATEMENT（默认）：每一条修改数据的SQL都会记录到binlog中，主从复制中slave端根据SQL语句重现。缺点是STATEMENT使用动态函数（uuid、now）时，主库执行的结果不是从库执行的结果，这会导致复制的数据不一致；
* ROW：记录行数据最终修改的情况，不会出现STATEMENT下动态函数的问题。缺点是每行数据变化结果都会被记录，批量update时会导致binlog过大；
* MIXED：包含STATEMENT和ROW模式，根据情况自动使用ROW和STATEMENT；

事务执行时，把日志写到binlog cache中，事务提交时，再把binlog cache写到binlog文件中，使用```sync_binlog```参数控制刷盘策略，0由操作系统决定，1马上刷盘，N积累N个事务刷盘；

### binlog主从复制

1. 写入binlog：主库写binlog，提交日志，更新本地数据；
2. 同步binlog：复制binlog到所有从库，从库把binlog写到暂存日志中；
3. 回放binlog：回放binlog，更新存储引擎中数据；

主从复制模型：
* 同步复制：主库等待从库复制成功响应，再返回客户端结果。缺点：性能差、可用性差
* 异步复制（默认）：主库无需等待从库响应，立即返回客户端结果。缺点：主库宕机会导致数据丢失
* 半同步复制：MySQL5.7后新增，主库等待部分从库复制成功响应，再返回客户端，兼顾同步和异步优点；

### 两阶段提交

redo log和binlog都需要持久化到磁盘上，但二者的持久化过程是独立的，可能出现半成功状态导致日志不一致，由于redo log影响主库数据，binlog影响从库数据，又会导致主从库数据不一致问题；

使用两阶段提交来解决日志不一致问题，将单个事务提交分为2个阶段：准备(prepare)阶段和提交(commit)阶段，每个阶段由协调者和参与者共同完成（在这里binlog为协调者，存储引擎是参与者）；

客户端执行commit语句或自动提交事务时，MySQL内部会开启一个XA事务，分两阶段来完成XA事务的提交

* prepare阶段：将XID（内部XA事务的ID）写入到redo log，同时及那个redo log对应的事务状态设置为prepare，然后将redo log持久化到磁盘；
* commit阶段：将XID写入到binlog，然后将binlog持久化到磁盘，接着调用引擎提交事务接口，将redo log状态设置为commit，只要binlog刷盘成功，redo log无论是prepare还是commit阶段，都能认定事务执行成功；

缺点：
* 磁盘I/O次数高：每次事务提交都会进行两次刷盘；
* 锁竞争激烈：在多事务情况下，需要加锁保证提交原子性以保证多事务下两个日志提交顺序的一致；

## 内存

### Buffer Pool

MySQL更新数据时，从磁盘中读取数据，在内存中更新数据，然后将数据缓存到Buffer Pool中，再进行落盘，以减少磁盘I/O、加速写操作、异步刷盘、支持高效并发访问、配合redo log实现崩溃恢复；

Buffer Pool以页为单位进行缓存，默认页大小为16KB，启动MySQL时，InnoDB为Buffer Pool申请一片连续内存空间（默认128MB，可通过```innodb_buffer_pool_size```参数设置，建议大小为物理内存的60%~80%），按16KB大小划分页（初始为空闲页），使用改进LRU算法进行缓存管理，除了缓存索引页和数据页外，还缓存undo页、插入缓存页、自适应哈希索引、锁信息等。

InnoDB为每个缓存页创建了一个控制块用于管理缓存页缓存页，放在Buffer Pool的最前面，控制块信息包括缓存页的表空间、页号、缓存页地址、链表节点等，控制块和缓存页之间存在碎片空间；
[](./assets/buffer%20pool%20control%20block.webp)

为了能快速找到空闲缓存页，使用链表结构，将空闲缓存页的控制块作为链表节点，这个链表称为**Free链表**，Free链表的头结点包含了链表的头结点地址、尾结点地址、结点数量等信息，其余结点包含控制块地址以及前后链表结点的地址；

为保证写的高性能，更新数据时，先不写入磁盘，而是将Buffer Pool对应的缓存页标记为**脏页**，再由后台线程写入磁盘，为了能快速找到脏页，设计出了**Flush**链表，与Free链表类似；

由上述描述可知，Buffer Pool中共有3种页和链表来管理数据
* Free Page（空闲页）：表示此页未被使用，位于Free链表；
* Clean Page（干净页）：表示此页被使用，但页面未发生修改，位于LRU链表；
* Dirty Page（脏页）：表示此页已被使用且已被修改，其数据与磁盘数据不一致，当脏页数据写入磁盘后，该页就变为了干净页。脏页可同时存在于LRU链表和Flush链表中；

Buffer Pool使用LRU算法提高缓存命中率，但并非简单LRU算法，因为简单LRU无法避免两个问题：
* 预读失效：MySQL的预读机制会在加载数据页时把相邻的数据页一并加载进来，但这些页可能并没有被访问，这就是预读失效；使用简单LRU算法会导致预读页占据链表位置而把频繁访问的页淘汰，使命中率降低
* Buffer Pool污染：当扫描了大量（不是查询，而是扫描）的数据时，会导致Buffer Pool中的所有页都被替换出去，导致热数据被淘汰，导致再次访问热数据时无法命中缓存；

改进方法：
* 预读失效：将LRU划分为2个区域：old区域和young区域，young区域位于LRU前半部分，old区域位于LRU后半部分，长度比例为63:37，预读的页加入到old区域头部，只有真正访问时才将其移动到young区域头部
* Buffer Pool污染：增加一个进入young区域的条件：判断页停留在old区域的时间。若后续访问时间与第一次访问时间间隔端，则认为是一次性扫描，保留在old区，否则认为是热点数据，将其移动到young区；